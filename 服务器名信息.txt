腾讯服务器
公网IP:123.207.171.22
服务器名：zqb
用户名：ubuntu
密码：2011zqb,.

腾讯服务器
公网IP:123.207.165.243
服务器名：zqb_1
用户名：ubuntu
密码：2011zqb,.

腾讯服务器
公网IP:140.143.6.130
服务器名：
用户名：root
密码：2011zqb,.


阿里服务器
公网IP:39.107.118.174
服务器名：zqb_2
用户名：root
密码：2011zqb,.
远程连接密码：299951


阿里云账号：zqb1120142028
密码：2014zqb



tar -zxvf jdk-8u161-linux-x64.tar.gz
cp -i /usr/profile /etc
source /etc/profile


http://apache.fayea.com/zookeeper/zookeeper-3.4.11/zookeeper-3.4.11.tar.gz



cd /usr/kafka/kafka_2.11-1.0.1/bin
source /usr/kafka/kafka_2.11-1.0.1/config/server.properties


启动zk服务
bin/zookeeper-server-start.sh config/zookeeper.properties
启动kafka服务，其中">>/dev/null"表示将日志信息输出到"黑洞"，其中"2>&1"表示将错误信息和前面的日志信息一样，也输出到"黑洞"，末尾的"&"表示以后台方式启动kafka：
bin/kafka-server-start.sh config/server.properties >>/dev/null 2>&1 &
bin/kafka-server-stop.sh config/server.properties
在一台机器上创建一个主题 39.107.118.174
bin/kafka-topics.sh --create --zookeeper master:2181,slave1:2181,slave2:2181 --replication-factor 3 --partitions 3 --topic mytest

bin/kafka-topics.sh --list --zookeeper master:2181,slave1:2181,slave2:2181

bin/kafka-topics.sh --describe --zookeeper master:2181,slave1:2181,slave2:2181 --topic mytest

bin/kafka-topics.sh --delete --zookeeper master:2181,slave1:2181,slave2:2181 --topic mytest


在一台机器上创建一个发布者123.207.165.243
bin/kafka-console-producer.sh --broker-list master:9092 --topic mytest

在一台机器上创建一个订阅者 
--from-beginning表示从头读取，只要log没被删除且在有效期内都会将该topic所有数据从头读取，如果要最新的数据,可以不带--from-beginning参数即可
bin/kafka-console-consumer.sh --zookeeper master:2181 --topic mytest --from-beginning



#添加服务节点，单节点服务，如下:
#2888端口号是zookeeper服务之间通信的端口号 
#3888端口号是zookeeper与其他应用程序通信的端口 
#server
server.0 = 39.107.118.174:2888:3888
server.1 = 123.207.165.243:2888:3888
server.2 = 123.207.171.22:2888:3888



cp config/server.properties config/server1.properties



cd /usr/kafka1/kafka_2.11-1.0.1
启动zookeeper服务
bin/zookeeper-server-start.sh config/zookeeper.properties
启动kafka服务
bin/kafka-server-start.sh config/server.properties


bin/kafka-console-producer.sh --broker-list master:9092,slave1:9092,slave2:9092 --topic test

bin/kafka-console-consumer.sh --zookeeper master:2181,slave1:2181,slave2:2181 --from-beginning --topic test










broker.id=1  
#当前机器在集群中的唯一标识，和zookeeper的myid性质一样  
port=9092 
#当前kafka对外提供服务的端口默认是9092  
host.name=192.168.47.128 
#这个参数默认是关闭的，在0.8.1有个bug，DNS解析问题，失败率的问题。  
num.network.threads=3 
#这个是borker进行网络处理的线程数  
num.io.threads=8 
#这个是borker进行I/O处理的线程数  
log.dirs=/usr/kafka/kafka_2.12-1.1.0/logs/ 
#消息存放的目录，这个目录可以配置为“，”逗号分割的表达式，上面的num.io.threads要大于这个目录的个数这个目录，如果配置多个目录，新创建的topic他把消息持久化的地方是，当前以逗号分割的目录中，那个分区数最少就放那一个  
socket.send.buffer.bytes=102400 
#发送缓冲区buffer大小，数据不是一下子就发送的，先回存储到缓冲区了到达一定的大小后在发送，能提高性能  
socket.receive.buffer.bytes=102400 
#kafka接收缓冲区大小，当数据到达一定大小后在序列化到磁盘  
socket.request.max.bytes=104857600 
#这个参数是向kafka请求消息或者向kafka发送消息的请请求的最大数，这个值不能超过java的堆栈大小  
num.partitions=1 
#默认的分区数，一个topic默认1个分区数  
log.retention.hours=168 
#默认消息的最大持久化时间，168小时，7天  
delete.topic.enable=true
message.max.byte=5242880  
#消息保存的最大值5M  
default.replication.factor=2  
#kafka保存消息的副本数，如果一个副本失效了，另一个还可以继续提供服务  
replica.fetch.max.bytes=5242880  
#取消息的最大直接数  
log.segment.bytes=1073741824 
#这个参数是：因为kafka的消息是以追加的形式落地到文件，当超过这个值的时候，kafka会新起一个文件  
log.retention.check.interval.ms=300000 
#每隔300000毫秒去检查上面配置的log失效时间（log.retention.hours=168 ），到目录查看是否有过期的消息如果有，删除  
log.cleaner.enable=false 
#是否启用log压缩，一般不用启用，启用的话可以提高性能  
zookeeper.connect=192.168.47.128:2181,192.168.47.129:2181,192.168.47.130:2181 
#设置zookeeper的连接端口 


140.143.6.130 master VM_148_106_centos
123.207.165.243 slave1 VM_8_2_centos
123.207.171.22 slave2 VM_46_223_centos